# Network Properties Outlier
# October 1, 2019
# Mark R. Bower
# Yale University
#
# create table tasks (nodename varchar(128),path varchar(256),data varchar(64),institution varchar(64),lab varchar(32),experiment varchar(32),subject int(11),signaltype varchar(32),iterationtype varchar(32),label varchar(512) not null,centerTime bigint,done boolean,created timestamp default current_timestamp, modified timestamp default current_timestamp on update current_timestamp, primary key (label) );
#
NPO_window_testbed <- function(...) {
  #' Run the Network Parameter Outlier (NPO) algorithm.
  #' 
  #' @export
  #' @examples
  #' \dontrun{
  #'   First time the function is called:
  #'   NPO_window(dbName='NSME_halo',path='NPO/Analysis/NPO/tests/testData/Halo/11',data='rodentMSO',institution='Yale',lab='NSME',experiment='Halo10sec_10x',subject=11,signalType='AP',centerTime=0,iterationType='directory',range=c(-3000,2000), '--restart' )
  #'
  #' ... or ...
  #' 
  #'   NPO_window(dbName='NV', path='/Users/markrbower/Dropbox/Documents/Concepts/2019_11_19_NetworkParameterOutlier/mef2', data='NV_23_002', institution='Yale', lab='NSME', experiment='baseline', subject='23_002', signalType='IIS', centerTime=0, iterationType='directory', range=c(-3000,2000), '--restart' )
  #' 
  #'   NPO_window(service='NV', path='/Users/markrbower/Documents/Data/NV/NVC1001_24_005_2', taskName='preprocessing', institution='Yale', lab='NSME', experiment='NeuroVista', subject='24_005', signalType='IIS', centerTime=0, iterationType='directory', range=c(-3000,2000), '--restart' )
  #' 
  #'   Subsequent calls:
  #'   NPO()
  #' }

  library( RMySQL )
  #print( "In NPO_window_testbed")
  
  args <- list(...)
  
#  setwd( here() )

  options(warn=-1)
  options(stringsAsFactors = FALSE);

  topconnect::clearAllDBcons()

  dbName <- NPO:::parseArg( args, 'dbName' )
  hostname <- NPO:::parseArg( args, 'hostname' )
  if ( nchar(hostname) == 0 ) {
    hostname <- 'localhost'
  }
  db_user <- NPO:::parseArg( args, 'db_user' )
  if ( nchar(db_user) == 0 ) {
    db_user <- 'root'
  }
  password <- NPO:::parseArg( args, 'password' )
  if ( nchar(password) == 0 ) {
    password <- ''
  }

#  conn <- topconnect::db( db_user="root", dbName=dbName, hostname=hostname, password=password )
  #print( paste0( "NPO_window_testbed: db_user : ", db_user ) )
  #print( paste0( "NPO_window_testbed: dbname  : ", dbName  ) )
  #print( paste0( "NPO_window_testbed: hostname: ", hostname ) )
  #print( paste0( "NPO_window_testbed: password: ", password ) )
    conn <- DBI::dbConnect( RMySQL::MySQL(), user=db_user, password=password, host=hostname, dbname=dbName)
  #print( "Connected")
  # Evaluate the "tasks" table.
  context <- topconnect::getContextFromTaskTable( conn, args )
  #print( 'Getting parameters' )
  parameters <- NPO:::loadParameters( context )

# Skip for the testbed analysis
  # Load the seizure times from the tasks table, which takes into account functions that identify "valid" seizures.
  # This table is generated by ...
#  context <- updateContextWithValidSeizureInformation( conn, context )
  
  # Create database tables
  parameters$correlationWindow <- NPO:::parseArg( args, 'correlationWindow' )
  parameters$CCthreshold <- NPO:::parseArg( args, 'CCthreshold' )
  #print( paste0( "CW: ", parameters$correlationWindow) )  
  #print( paste0( "CC: ", parameters$CCthrehold) )
  
  # Merge context and parameters into one list
  #print( "Append variaables")
  variables <- append( context, parameters )
  if ( "dbName" %in% names(variables) ) {
    variables$dbName <- dbName
  } else {
    variables <- append( variables, list(dbName=dbName) )
  }
  if ( "hostname" %in% names(variables) ) {
    variables$hostname <- hostname
  } else {
    variables <- append( variables, list(hostname=hostname) )
  }
  if ( "db_user" %in% names(variables) ) {
    variables$db_user <- db_user
  } else {
    variables <- append( variables, list(db_user=db_user) )
  }
  if ( "password" %in% names(variables) ) {
    variables$password <- password
  } else {
    variables <- append( variables, list(password=password) )
  }

  #print( "Make table names" )
  table_names <- NPO:::createTablesForNPO( conn, variables )

  # I don't understand what the purpose of this function is. About the only useful thing is checking for a 'restart', which can be done on it's own.
  #  analysisPlan <- useArgsAndContextToPlan( conn, args, context )
  #print( "checkRestart")
  NPO:::checkRestart( args, conn, table_names, context )
#  checkMEFpassword( context ) # Make sure that the secret_vault has the correct password

  DBI::dbDisconnect( conn )
  # Find   the channel names and fill the progress table
  # Find peaks
  #print( "Into MEFthen ...")
  
  NPO:::MEFthenAnalysisLoopOnDirectory_testbed( variables, dbName, table_names, testbedFlag = TRUE )
  
  # Find communities
#  MySQL_analysisLoop_P2M_batch( parameters, dbName, table_names, context )
  
  # Find clusters
  # MySQL_analysisLoop_M2C_batch( conn, '', table_names, subject, seizureTime )
  

}
